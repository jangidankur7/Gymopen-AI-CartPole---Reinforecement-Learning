{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer games is an example for Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RL : Hit and Trial Method\n",
    "- Just like learning to ride a cycle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Its parts are :\n",
    "- ***AI Bot*** which intracts with the environment\n",
    "- Environment with a state\n",
    "- Agent interacts with environment with some action \n",
    "- That action will belong to a set of actions\n",
    "- Now, environment will return a state fromm the set of states to the agent\n",
    "- Environment will also giive some reward to agent along with state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching our AI bot:\n",
    "- We will use Gym openAI\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gym) (1.19.2)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gym) (7.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gym) (1.5.2)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loaded environment (game with name CartPole)\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMES WITH certain import methods :\n",
    "- action_space\n",
    "- observation_space\n",
    "- reset() : Returns init state and also resets the env\n",
    "- step()\n",
    "- render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03158367,  0.00335383, -0.00151384,  0.02523392])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset() ## Take game to initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space ## Means we can move only right or left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n ## 2 actions we can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "for t in range(1000):\n",
    "    random_action = env.action_space.sample()\n",
    "    env.step(random_action) ## randomly move lt or rt\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing CartPole with random statergy :\n",
    "- Game episode : We are going to play multiple games with different time duration\n",
    "- Step() function in more detail\n",
    "- game over ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :0/20 High Score :22\n",
      "Game Episode :1/20 High Score :45\n",
      "Game Episode :2/20 High Score :13\n",
      "Game Episode :3/20 High Score :15\n",
      "Game Episode :4/20 High Score :8\n",
      "Game Episode :5/20 High Score :9\n",
      "Game Episode :6/20 High Score :15\n",
      "Game Episode :7/20 High Score :12\n",
      "Game Episode :8/20 High Score :11\n",
      "Game Episode :9/20 High Score :36\n",
      "Game Episode :10/20 High Score :21\n",
      "Game Episode :11/20 High Score :15\n",
      "Game Episode :12/20 High Score :11\n",
      "Game Episode :13/20 High Score :13\n",
      "Game Episode :14/20 High Score :13\n",
      "Game Episode :15/20 High Score :14\n",
      "Game Episode :16/20 High Score :22\n",
      "Game Episode :17/20 High Score :11\n",
      "Game Episode :18/20 High Score :13\n",
      "Game Episode :19/20 High Score :10\n",
      "All 20 episodes are over\n"
     ]
    }
   ],
   "source": [
    "for e in range(20): ## we will play 20 games \n",
    "    #e = episode\n",
    "    observation = env.reset()\n",
    "    \n",
    "    for t in range(50):\n",
    "         # 50 timestep is maximum time for which we will play one episode or game\n",
    "            \n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation,reward,done,other_info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            \n",
    "            print(\"Game Episode :{}/{} High Score :{}\".format(e,20,t))\n",
    "            break\n",
    "            \n",
    "env.close()\n",
    "print(\"All 20 episodes are over\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q - Learning :\n",
    "- Building our own statergy\n",
    "- Q function : Q(s,a)\n",
    "- Q(s,a) where 's' is state and 'a' is action to take corrosponding to that state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bellman Equation:\n",
    "'''https://ai.stackexchange.com/questions/11057/what-is-the-bellman-operator-in-reinforcement-learning'''\n",
    "\n",
    "- Q(s,a) = r + (gamma) * MAX{Q(S_,a_)}\n",
    "- gamma = Discount Factor\n",
    "- r = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Design Exploration VS Exploitation Tradeoff\n",
    "- Exploration is good in begening : It helps us to try various random things\n",
    "- Exploitation is good at the end : It helps to sample good experience from the past(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self,state_size,action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95 ## Discount factor\n",
    "        self.epsilon = 1.0 ## 100% Random exploration in the begning\n",
    "        self.epsilon_decay = 0.995 ## It will trust the knowledge 0.05% from past experience and learn by exploration rest 99.5%\\\n",
    "        self.epsilon_min = 0.01 ##{Work at last when we gained full knowledge by playing lot of games}\n",
    "        ##Even if I have played 1000 games, I will take 1% random action and rest will be from past knowwledge\n",
    "        \n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._createmodel()\n",
    "        \n",
    "    def _createmodel(self):   \n",
    "        model = Sequential()\n",
    "        model.add(Dense(24,input_dim=self.state_size,activation='relu'))\n",
    "\n",
    "        model.add(Dense(24,activation='relu'))\n",
    "\n",
    "        model.add(Dense(self.action_size,activation='linear'))\n",
    "\n",
    "        model.compile(loss='mse',optimizer=Adam(lr = 0.001))\n",
    "\n",
    "        #model.summary()\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def remember(self,state,action,reward,next_state,done):\n",
    "        # Remember all past experiences\n",
    "        self.memory.append((state,action,reward,next_state,done))\n",
    "    \n",
    "    def act(self,state):\n",
    "        # Epsilon greedy method\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            ## In this case, take a random action \n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        ## In else case, we will ask NN to give a suitable action\n",
    "        \n",
    "        return np.argmax(model.predict(state)[0])\n",
    "    \n",
    "    \n",
    "    def train(self,batch_size):\n",
    "        # Train using Replay Buffer\n",
    "        \n",
    "        minibatch = random.sample(self.memory,batch_size)\n",
    "        \n",
    "        for experience in minibatch:\n",
    "            state,action,reward,next_state,done = experience\n",
    "            \n",
    "            ## X : State\n",
    "            ## Y : Expected Reward\n",
    "            \n",
    "            if not done:\n",
    "                # Gameis not yet over, Bellman eqn to approx the target_value of reward\n",
    "                \n",
    "                target = reward + self.gamma*np.amax(self.model.predict(next_state)[0])\n",
    "                \n",
    "            else:\n",
    "\n",
    "                target = reward\n",
    "\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "\n",
    "            # X = state\n",
    "            # Y = target_f\n",
    "\n",
    "            self.model.fit(state,target_f,epochs=1,verbose=0)\n",
    "                \n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                \n",
    "                self.epsilon *= self.epsilon_decay\n",
    "                \n",
    "    def load(self,name):\n",
    "        self.model.load_weights(name)\n",
    "        \n",
    "    def save(self,name):\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why agent needs a memory ?\n",
    "- You dont havve any training data\n",
    "- We will use past experiences of agent in memory to play the game \n",
    "- We will use that memory to train neural network \n",
    "\n",
    "- We will use double endded queue where we can add or remove items from both ends\n",
    "- We will remove old experience and add new experience to that memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Example of what model we are using\n",
    "model = Sequential()\n",
    "model.add(Dense(24,input_dim=4,activation='relu'))\n",
    "\n",
    "model.add(Dense(24,activation='relu'))\n",
    "\n",
    "model.add(Dense(2,activation='linear'))\n",
    "\n",
    "model.compile(loss='mse',optimizer=Adam(lr = 0.001))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06790003,  0.08345148]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(1,4)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the DQN Agent (Deep Q-Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1000\n",
    "output_dir = \"C:/Users/Asus/Desktop/carpole_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=4,action_size=2)\n",
    "done = False\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :0/20 High Score :10 Exploration Rate 1.0\n",
      "Game Episode :1/20 High Score :32 Exploration Rate 1.0\n",
      "Game Episode :2/20 High Score :13 Exploration Rate 0.85\n",
      "Game Episode :3/20 High Score :21 Exploration Rate 0.73\n",
      "Game Episode :4/20 High Score :12 Exploration Rate 0.62\n",
      "Game Episode :5/20 High Score :10 Exploration Rate 0.53\n",
      "Game Episode :6/20 High Score :10 Exploration Rate 0.45\n",
      "Game Episode :7/20 High Score :11 Exploration Rate 0.38\n",
      "Game Episode :8/20 High Score :10 Exploration Rate 0.33\n",
      "Game Episode :9/20 High Score :9 Exploration Rate 0.28\n",
      "Game Episode :10/20 High Score :8 Exploration Rate 0.24\n",
      "Game Episode :11/20 High Score :9 Exploration Rate 0.2\n",
      "Game Episode :12/20 High Score :8 Exploration Rate 0.17\n",
      "Game Episode :13/20 High Score :9 Exploration Rate 0.15\n",
      "Game Episode :14/20 High Score :9 Exploration Rate 0.12\n",
      "Game Episode :15/20 High Score :9 Exploration Rate 0.11\n",
      "Game Episode :16/20 High Score :7 Exploration Rate 0.09\n",
      "Game Episode :17/20 High Score :9 Exploration Rate 0.077\n",
      "Game Episode :18/20 High Score :9 Exploration Rate 0.065\n",
      "Game Episode :19/20 High Score :8 Exploration Rate 0.056\n",
      "Game Episode :20/20 High Score :7 Exploration Rate 0.047\n",
      "Game Episode :21/20 High Score :9 Exploration Rate 0.04\n",
      "Game Episode :22/20 High Score :8 Exploration Rate 0.034\n",
      "Game Episode :23/20 High Score :9 Exploration Rate 0.029\n",
      "Game Episode :24/20 High Score :10 Exploration Rate 0.025\n",
      "Game Episode :25/20 High Score :9 Exploration Rate 0.021\n",
      "Game Episode :26/20 High Score :7 Exploration Rate 0.018\n",
      "Game Episode :27/20 High Score :7 Exploration Rate 0.015\n",
      "Game Episode :28/20 High Score :9 Exploration Rate 0.013\n",
      "Game Episode :29/20 High Score :9 Exploration Rate 0.011\n",
      "Game Episode :30/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :31/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :32/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :33/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :34/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :35/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :36/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :37/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :38/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :39/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :40/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :41/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :42/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :43/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :44/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :45/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :46/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :47/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :48/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :49/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :50/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :51/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :52/20 High Score :11 Exploration Rate 0.01\n",
      "Game Episode :53/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :54/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :55/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :56/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :57/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :58/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :59/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :60/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :61/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :62/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :63/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :64/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :65/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :66/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :67/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :68/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :69/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :70/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :71/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :72/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :73/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :74/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :75/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :76/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :77/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :78/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :79/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :80/20 High Score :11 Exploration Rate 0.01\n",
      "Game Episode :81/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :82/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :83/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :84/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :85/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :86/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :87/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :88/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :89/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :90/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :91/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :92/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :93/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :94/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :95/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :96/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :97/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :98/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :99/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :100/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :101/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :102/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :103/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :104/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :105/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :106/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :107/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :108/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :109/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :110/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :111/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :112/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :113/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :114/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :115/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :116/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :117/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :118/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :119/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :120/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :121/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :122/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :123/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :124/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :125/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :126/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :127/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :128/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :129/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :130/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :131/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :132/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :133/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :134/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :135/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :136/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :137/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :138/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :139/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :140/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :141/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :142/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :143/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :144/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :145/20 High Score :8 Exploration Rate 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :146/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :147/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :148/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :149/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :150/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :151/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :152/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :153/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :154/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :155/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :156/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :157/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :158/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :159/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :160/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :161/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :162/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :163/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :164/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :165/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :166/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :167/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :168/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :169/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :170/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :171/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :172/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :173/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :174/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :175/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :176/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :177/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :178/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :179/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :180/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :181/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :182/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :183/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :184/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :185/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :186/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :187/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :188/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :189/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :190/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :191/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :192/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :193/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :194/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :195/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :196/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :197/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :198/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :199/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :200/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :201/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :202/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :203/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :204/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :205/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :206/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :207/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :208/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :209/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :210/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :211/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :212/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :213/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :214/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :215/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :216/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :217/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :218/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :219/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :220/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :221/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :222/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :223/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :224/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :225/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :226/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :227/20 High Score :11 Exploration Rate 0.01\n",
      "Game Episode :228/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :229/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :230/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :231/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :232/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :233/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :234/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :235/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :236/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :237/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :238/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :239/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :240/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :241/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :242/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :243/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :244/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :245/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :246/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :247/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :248/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :249/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :250/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :251/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :252/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :253/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :254/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :255/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :256/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :257/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :258/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :259/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :260/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :261/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :262/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :263/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :264/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :265/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :266/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :267/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :268/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :269/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :270/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :271/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :272/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :273/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :274/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :275/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :276/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :277/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :278/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :279/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :280/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :281/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :282/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :283/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :284/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :285/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :286/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :287/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :288/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :289/20 High Score :9 Exploration Rate 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :290/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :291/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :292/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :293/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :294/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :295/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :296/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :297/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :298/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :299/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :300/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :301/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :302/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :303/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :304/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :305/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :306/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :307/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :308/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :309/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :310/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :311/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :312/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :313/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :314/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :315/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :316/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :317/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :318/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :319/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :320/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :321/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :322/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :323/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :324/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :325/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :326/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :327/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :328/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :329/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :330/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :331/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :332/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :333/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :334/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :335/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :336/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :337/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :338/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :339/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :340/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :341/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :342/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :343/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :344/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :345/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :346/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :347/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :348/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :349/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :350/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :351/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :352/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :353/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :354/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :355/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :356/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :357/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :358/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :359/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :360/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :361/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :362/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :363/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :364/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :365/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :366/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :367/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :368/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :369/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :370/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :371/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :372/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :373/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :374/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :375/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :376/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :377/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :378/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :379/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :380/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :381/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :382/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :383/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :384/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :385/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :386/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :387/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :388/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :389/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :390/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :391/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :392/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :393/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :394/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :395/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :396/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :397/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :398/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :399/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :400/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :401/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :402/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :403/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :404/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :405/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :406/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :407/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :408/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :409/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :410/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :411/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :412/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :413/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :414/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :415/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :416/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :417/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :418/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :419/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :420/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :421/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :422/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :423/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :424/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :425/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :426/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :427/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :428/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :429/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :430/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :431/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :432/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :433/20 High Score :9 Exploration Rate 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Episode :434/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :435/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :436/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :437/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :438/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :439/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :440/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :441/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :442/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :443/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :444/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :445/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :446/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :447/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :448/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :449/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :450/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :451/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :452/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :453/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :454/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :455/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :456/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :457/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :458/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :459/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :460/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :461/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :462/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :463/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :464/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :465/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :466/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :467/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :468/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :469/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :470/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :471/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :472/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :473/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :474/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :475/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :476/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :477/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :478/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :479/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :480/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :481/20 High Score :11 Exploration Rate 0.01\n",
      "Game Episode :482/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :483/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :484/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :485/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :486/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :487/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :488/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :489/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :490/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :491/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :492/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :493/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :494/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :495/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :496/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :497/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :498/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :499/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :500/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :501/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :502/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :503/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :504/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :505/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :506/20 High Score :10 Exploration Rate 0.01\n",
      "Game Episode :507/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :508/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :509/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :510/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :511/20 High Score :9 Exploration Rate 0.01\n",
      "Game Episode :512/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :513/20 High Score :8 Exploration Rate 0.01\n",
      "Game Episode :514/20 High Score :7 Exploration Rate 0.01\n",
      "Game Episode :515/20 High Score :8 Exploration Rate 0.01\n"
     ]
    }
   ],
   "source": [
    "for e in range(n_episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state,[1,state_size])\n",
    "    \n",
    "    for time in range(5000):\n",
    "        \n",
    "        env.render()\n",
    "        action = agent.act(state) ## Action is 0 or 1\n",
    "        next_state,reward,done,other_info = env.step(action)\n",
    "        reward = reward if not done else -10  ########## IMPORTANT #########\n",
    "        next_state = np.reshape(next_state,[1,state_size])\n",
    "        agent.remember(state,action,reward,next_state,done) ## Experience for the agent\n",
    "        \n",
    "        \n",
    "        if done:\n",
    "            \n",
    "            print(\"Game Episode :{}/{} High Score :{} Exploration Rate {:.2}\".format(e,20,time,agent.epsilon))\n",
    "            break\n",
    "            \n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.train(batch_size)\n",
    "        \n",
    "    if e%50 == 0:\n",
    "        agent.save(output_dir+\"weights_\"+'{:04d}'.format(e)+\".hdf5\")\n",
    "\n",
    "print(\"Deep Q-Learner Model trained\")\n",
    "env.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
